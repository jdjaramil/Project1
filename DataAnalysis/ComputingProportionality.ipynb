{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8385529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import pysentiment2 as ps\n",
    "import nltk\n",
    "import pysentiment2 as ps\n",
    "from nltk.stem.porter import *\n",
    "import os\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bba8539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11383, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JuliJaramillo\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (9) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\JuliJaramillo\\AppData\\Local\\Temp\\ipykernel_8464\\151399494.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  df['cik'] = df['cik'].astype(np.int).astype(str).str.pad(10, fillchar='0')\n"
     ]
    }
   ],
   "source": [
    "#Load the Returns file\n",
    "df = pd.read_csv('../DataRetrieval/url_with_returns.csv')[['reportDate','filingDate', 'cik', 'ExcessReturnsEqualWeightedSnP', 'ExcessReturnsValueWeightedSnP']]\n",
    "df['cik'] = df['cik'].astype(np.int).astype(str).str.pad(10, fillchar='0')\n",
    "# Filtering out returns on or after 2016-01-01\n",
    "df = df[df.reportDate >= '2016-01-01']\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1fbfbfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reportDate</th>\n",
       "      <th>filingDate</th>\n",
       "      <th>cik</th>\n",
       "      <th>ExcessReturnsEqualWeightedSnP</th>\n",
       "      <th>ExcessReturnsValueWeightedSnP</th>\n",
       "      <th>propLM</th>\n",
       "      <th>propHar</th>\n",
       "      <th>weightedLM</th>\n",
       "      <th>weightedHar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>2016-05-09</td>\n",
       "      <td>0000814453</td>\n",
       "      <td>0.015216</td>\n",
       "      <td>0.012411</td>\n",
       "      <td>0.027910</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.029333</td>\n",
       "      <td>0.026957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>2016-08-09</td>\n",
       "      <td>0000814453</td>\n",
       "      <td>0.010468</td>\n",
       "      <td>0.012448</td>\n",
       "      <td>0.026423</td>\n",
       "      <td>0.073618</td>\n",
       "      <td>0.022645</td>\n",
       "      <td>0.021967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>2016-11-08</td>\n",
       "      <td>0000814453</td>\n",
       "      <td>-0.077190</td>\n",
       "      <td>-0.069763</td>\n",
       "      <td>0.028069</td>\n",
       "      <td>0.076594</td>\n",
       "      <td>0.024874</td>\n",
       "      <td>0.025146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>0000814453</td>\n",
       "      <td>-0.000803</td>\n",
       "      <td>-0.003919</td>\n",
       "      <td>0.028890</td>\n",
       "      <td>0.075044</td>\n",
       "      <td>0.024955</td>\n",
       "      <td>0.027954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>2017-05-10</td>\n",
       "      <td>0000814453</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>-0.002548</td>\n",
       "      <td>0.025452</td>\n",
       "      <td>0.075698</td>\n",
       "      <td>0.030192</td>\n",
       "      <td>0.030750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20726</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>0001682852</td>\n",
       "      <td>-0.174756</td>\n",
       "      <td>-0.166301</td>\n",
       "      <td>0.020214</td>\n",
       "      <td>0.072817</td>\n",
       "      <td>0.006567</td>\n",
       "      <td>0.032208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20727</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>2021-11-08</td>\n",
       "      <td>0000842023</td>\n",
       "      <td>0.004587</td>\n",
       "      <td>0.011895</td>\n",
       "      <td>0.014241</td>\n",
       "      <td>0.064210</td>\n",
       "      <td>0.006367</td>\n",
       "      <td>0.008581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20728</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>2021-11-08</td>\n",
       "      <td>0000891103</td>\n",
       "      <td>-0.035377</td>\n",
       "      <td>-0.028070</td>\n",
       "      <td>0.035195</td>\n",
       "      <td>0.072138</td>\n",
       "      <td>0.037698</td>\n",
       "      <td>0.033316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20729</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>0001725057</td>\n",
       "      <td>-0.039414</td>\n",
       "      <td>-0.041318</td>\n",
       "      <td>0.023269</td>\n",
       "      <td>0.081838</td>\n",
       "      <td>0.017123</td>\n",
       "      <td>0.020058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20730</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>2021-10-26</td>\n",
       "      <td>0000079282</td>\n",
       "      <td>-0.007397</td>\n",
       "      <td>-0.019200</td>\n",
       "      <td>0.018585</td>\n",
       "      <td>0.066441</td>\n",
       "      <td>0.005843</td>\n",
       "      <td>0.007260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11383 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       reportDate  filingDate         cik  ExcessReturnsEqualWeightedSnP  \\\n",
       "20     2016-03-31  2016-05-09  0000814453                       0.015216   \n",
       "21     2016-06-30  2016-08-09  0000814453                       0.010468   \n",
       "22     2016-09-30  2016-11-08  0000814453                      -0.077190   \n",
       "23     2016-12-31  2017-03-01  0000814453                      -0.000803   \n",
       "24     2017-03-31  2017-05-10  0000814453                       0.001553   \n",
       "...           ...         ...         ...                            ...   \n",
       "20726  2021-09-30  2021-11-04  0001682852                      -0.174756   \n",
       "20727  2021-09-30  2021-11-08  0000842023                       0.004587   \n",
       "20728  2021-09-30  2021-11-08  0000891103                      -0.035377   \n",
       "20729  2021-09-30  2021-11-03  0001725057                      -0.039414   \n",
       "20730  2021-09-30  2021-10-26  0000079282                      -0.007397   \n",
       "\n",
       "       ExcessReturnsValueWeightedSnP    propLM   propHar  weightedLM  \\\n",
       "20                          0.012411  0.027910  0.074000    0.029333   \n",
       "21                          0.012448  0.026423  0.073618    0.022645   \n",
       "22                         -0.069763  0.028069  0.076594    0.024874   \n",
       "23                         -0.003919  0.028890  0.075044    0.024955   \n",
       "24                         -0.002548  0.025452  0.075698    0.030192   \n",
       "...                              ...       ...       ...         ...   \n",
       "20726                      -0.166301  0.020214  0.072817    0.006567   \n",
       "20727                       0.011895  0.014241  0.064210    0.006367   \n",
       "20728                      -0.028070  0.035195  0.072138    0.037698   \n",
       "20729                      -0.041318  0.023269  0.081838    0.017123   \n",
       "20730                      -0.019200  0.018585  0.066441    0.005843   \n",
       "\n",
       "       weightedHar  \n",
       "20        0.026957  \n",
       "21        0.021967  \n",
       "22        0.025146  \n",
       "23        0.027954  \n",
       "24        0.030750  \n",
       "...            ...  \n",
       "20726     0.032208  \n",
       "20727     0.008581  \n",
       "20728     0.033316  \n",
       "20729     0.020058  \n",
       "20730     0.007260  \n",
       "\n",
       "[11383 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13fc9471",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JuliJaramillo\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:312: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#Define the dictionaries\n",
    "\n",
    "LMDictionary = pd.read_excel('LM_Neg.xlsx', sheet_name = 'ND_FinTerms_Negative_v2', header = None).values.reshape(-1)\n",
    "LMDictionary = set( [w.lower().strip() for w in LMDictionary ] )\n",
    "\n",
    "HarvardDictionary = list(open('Harvard_Neg_Inf.txt', 'r'))\n",
    "HarvardDictionary = set ( [w.strip().lower() for w in HarvardDictionary ] )\n",
    "\n",
    "\n",
    "#Define the stopwords dictionary\n",
    "stop_words = list(set(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8de3e0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Harvard,LM and stopwords is 2337 4187 179\n"
     ]
    }
   ],
   "source": [
    "print('Length of Harvard,LM and stopwords is', len(LMDictionary ), len(HarvardDictionary), len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9105d52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_words(words):\n",
    "    lemmatized_words = [WordNetLemmatizer().lemmatize(word, 'v') for word in words]\n",
    "    return lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50b7f181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize Dictionaries and stop words\n",
    "stop_words = set(lemmatize_words(stopwords.words('english')))\n",
    "HarvardDictionary = set(lemmatize_words(HarvardDictionary))\n",
    "LMDictionary = set(lemmatize_words(LMDictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03435ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Harvard,LM and stopwords is 1495 2388 166\n"
     ]
    }
   ],
   "source": [
    "print('Length of Harvard, LM and stopwords is', len(LMDictionary ), len(HarvardDictionary), len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "464589e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#listFileNames = os.listdir('../Forms/')\n",
    "listFileNames = os.listdir('../DataRetrieval/Forms/')\n",
    "\n",
    "# Calculates the total number of documents under consideration\n",
    "N = 0\n",
    "\n",
    "# Calculate the number of documents in which a word has appeared \n",
    "globalDict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d417961",
   "metadata": {},
   "source": [
    "This loop computes the value of N and compute a dictionary that counts the number of documents in which a word has appeared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f142c8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n"
     ]
    }
   ],
   "source": [
    "for row, fileName in enumerate(listFileNames):\n",
    "    \n",
    "    cik = fileName.split('_')[0]\n",
    "    filingDate = fileName.split('_')[1].split('.')[0]\n",
    "    #path = '../Forms/{}_{}.txt'.format(cik, filingDate)\n",
    "\n",
    "    path = '../DataRetrieval/Forms/{}_{}.txt'.format(cik, filingDate)\n",
    "    \n",
    "    f = open(path, \"r\")\n",
    "    text = f.read()\n",
    "    \n",
    "    tokensOwn = nltk.word_tokenize(text)\n",
    "    tokensOwn= list(lemmatize_words(tokensOwn))\n",
    "\n",
    "    # Filtering out the documents where the numbers of words are less than 2000\n",
    "    if len(tokensOwn) >= 2000:       \n",
    "        N+=1\n",
    "        filteredText = [w for w in tokensOwn if not w in stop_words]\n",
    "        \n",
    "        # Updated the global_dict to include count of words observed in the current document\n",
    "        #Number of documents that contains the token \"word\"\n",
    "        #Df_i\n",
    "        for word in list(set(filteredText)):\n",
    "            if not word in globalDict:\n",
    "                globalDict[word] = 1\n",
    "            else:\n",
    "                globalDict[word] += 1\n",
    "        \n",
    "    f.close()\n",
    "    \n",
    "    if (row % 1000 == 0) & (row != 0): \n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "804eb757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents under consideration: 11360\n"
     ]
    }
   ],
   "source": [
    "print('Total number of documents under consideration:', N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ada2be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of distinct words across all documents: 245178\n"
     ]
    }
   ],
   "source": [
    "print('Total number of distinct words across all documents:', len(globalDict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d92eba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordCountDictionary(documentTokens):\n",
    "    '''\n",
    "    Counting occurrences of a given word in a document. EVERY WORD, not just the negative words. (TF_ij)\n",
    "    documentTokens: (list) tokens of the document\n",
    "    '''\n",
    "    \n",
    "    documentWordCountDict = {}\n",
    "    for word in list(documentTokens):\n",
    "        if not word in documentWordCountDict:\n",
    "            documentWordCountDict[word] = 1\n",
    "        else:\n",
    "            documentWordCountDict[word] += 1\n",
    "            \n",
    "    return documentWordCountDict     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b0df42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countNegativeWords(documentTokens, setNegativeWords):\n",
    "    '''\n",
    "    Counts negative words specified in setNegativeWords given the documentTokens\n",
    "    '''\n",
    "    countNegativeWords = 0\n",
    "    for word in documentTokens:\n",
    "        if word in setNegativeWords:\n",
    "            countNegativeWords+=1\n",
    "    return countNegativeWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfa8913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightedNegativeWords(documentTokens, setNegativeWords, wordWeights):\n",
    "    '''\n",
    "    Counts weighted (wordWeights) proportion of negative words specified in setNegativeWords given the documentTokens\n",
    "    '''\n",
    "    \n",
    "    weightedNegativeWords = 0.0\n",
    "    weightedWords = 0.0\n",
    "    for word in documentTokens:\n",
    "        weightedWords += wordWeights[word]\n",
    "        if word in setNegativeWords:\n",
    "            weightedNegativeWords += wordWeights[word]\n",
    "            \n",
    "    return weightedNegativeWords/weightedWords\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a270d31",
   "metadata": {},
   "source": [
    "This loop iterates over all documents and computes the proportion of negative words both unweighted and weighted using the Harvard and LM Dictionaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89395fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n"
     ]
    }
   ],
   "source": [
    "for row, fileName in enumerate(listFileNames):\n",
    "    \n",
    "    cik = fileName.split('_')[0]\n",
    "    filingDate = fileName.split('_')[1].split('.')[0]\n",
    "    #path = '../Forms/{}_{}.txt'.format(cik, filingDate)\n",
    "\n",
    "    path = '../DataRetrieval/Forms/{}_{}.txt'.format(cik, filingDate)\n",
    "    \n",
    "    f = open(path, \"r\")\n",
    "    text = f.read()\n",
    "    \n",
    "    tokensOwn = nltk.word_tokenize(text)\n",
    "    tokensOwn= list(lemmatize_words(tokensOwn))\n",
    "\n",
    "    # Filtering out the documents where the numbers of words are less than 2000\n",
    "    if len(tokensOwn) >= 2000:       \n",
    "        filteredText = [w for w in tokensOwn if not w in stop_words]\n",
    "        \n",
    "        numeratorLM = countNegativeWords(filteredText, LMDictionary)\n",
    "        propLM = numeratorLM/len(filteredText)\n",
    "        \n",
    "        numeratorHar = countNegativeWords(filteredText, HarvardDictionary)\n",
    "        propHar = numeratorHar/len(filteredText)\n",
    "        \n",
    "        df.loc[(df['cik']== cik) & (df['filingDate'] == filingDate), 'propLM'] = propLM \n",
    "        df.loc[(df['cik']== cik) & (df['filingDate'] == filingDate), 'propHar'] = propHar\n",
    "        \n",
    "        \n",
    "        wCountDictionary = wordCountDictionary(filteredText)\n",
    "        a = np.mean(list(wCountDictionary.values()))\n",
    "        \n",
    "        wordWeights = {}\n",
    "        \n",
    "        for word, word_count in wCountDictionary.items():\n",
    "            wordWeights[word] = (1 + np.log(wCountDictionary[word]))*(np.log(N/globalDict[word]))/(1 + np.log(a))\n",
    "        \n",
    "        \n",
    "        weightedLM = weightedNegativeWords(filteredText, LMDictionary, wordWeights)\n",
    "        weightedHar = weightedNegativeWords(filteredText, HarvardDictionary, wordWeights)\n",
    "        \n",
    "        df.loc[(df['cik']== cik) & (df['filingDate'] == filingDate), 'weightedLM'] = weightedLM \n",
    "        df.loc[(df['cik']== cik) & (df['filingDate'] == filingDate), 'weightedHar'] = weightedHar \n",
    "                \n",
    "    f.close()\n",
    "    \n",
    "    if (row % 1000 == 0) & (row != 0): \n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c259c2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = df[df['propLM'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad8edde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('proportions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
